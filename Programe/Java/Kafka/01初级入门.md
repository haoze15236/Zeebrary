# 环境准备

## zookeeper

```shell
#由于Kafka是用Scala语言开发的，运行在JVM上，因此在安装Kafka之前需要先安装JDK。
yum install java-1.8.0-openjdk* -y
#kafka依赖zookeeper，所以需要先安装zookeeper
wget http://mirror.bit.edu.cn/apache/zookeeper/stable/zookeeper-3.4.12.tar.gz
```

此时可能出现错误:

```
-bash: wget http://mirror.bit.edu.cn/apache/zookeeper/stable/zookeeper-3.4.12.tar.gz: No such file or directory
```

可能由于版本更新文件不存在,在浏览器中输入`http://mirror.bit.edu.cn/apache/zookeeper/stable`查看当前版本下载即可,笔者下载时已更新到3.5.9版本

![image-20210116194333648](C:\Users\zee\AppData\Roaming\Typora\typora-user-images\image-20210116194333648.png)

其中bin版本才是可以直接使用的二进制包,第二个为源码包,无法直接使用。

```shell
#下载bin版本
wget http://mirror.bit.edu.cn/apache/zookeeper/stable/apache-zookeeper-3.5.9-bin.tar.gz
```

```shell
#解压
tar -zxvf zookeeper-3.4.12.tar.gz
cd zookeeper-3.4.12
cp conf/zoo_sample.cfg conf/zoo.cfg

#启动zookeeper
bin/zkServer.sh start
bin/zkCli.sh
ls / #查看zk的根目录相关节点
```

## kafka

### 下载安装包

```shell
#https://archive.apache.org/dist/kafka下可选择下载版本
wget https://archive.apache.org/dist/kafka/1.1.0/kafka_2.11-1.1.0.tgz
tar -xzf kafka_2.11-1.1.0.tgz
cd kafka_2.11-1.1.0
```

### 启动服务

通过此命令,我们就创建了<a href="./00概念介绍#concept">概念介绍</a>中的broker。

```shell
#启动语句: 表示运行bin/kafka-server-start.sh脚本文件
#-daemon表示后台运行
#config/server.properties表示使用此配置文件启动服务
bin/kafka-server-start.sh -daemon config/server.properties
```

通过指定不同的config/server.properties，可创建不同属性的broker,关于server.properties配置属性解释如下：

| **Property**               | **Default**                     | **Description**                                              |
| -------------------------- | ------------------------------- | ------------------------------------------------------------ |
| broker.id                  | 0                               | 每个broker都可以用一个唯一的非负整数id进行标识；这个id可以作为broker的“名字”，你可以选择任意你喜欢的数字作为id，只要id是唯一的即可。 |
| log.dirs                   | /tmp/kafka-logs                 | kafka存放数据的路径。这个路径并不是唯一的，可以是多个，路径之间只需要使用逗号分隔即可；每当创建新partition时，都会选择在包含最少partitions的路径下进行。 |
| listeners                  | PLAINTEXT://192.168.124.16:9092 | server接受客户端连接的端口，ip配置kafka本机ip即可            |
| zookeeper.connect          | localhost:2181                  | zooKeeper连接字符串的格式为：hostname:port，此处hostname和port分别是ZooKeeper集群中某个节点的host和port；zookeeper如果是集群，连接方式为 hostname1:port1, hostname2:port2, hostname3:port3 |
| log.retention.hours        | 168                             | 每个日志文件删除之前保存的时间。默认数据保存时间对所有topic都一样。 |
| num.partitions             | 1                               | 创建topic的默认分区数                                        |
| default.replication.factor | 1                               | 自动创建topic的默认副本数量，建议设置为大于等于2             |
| min.insync.replicas        | 1                               | 当producer设置acks为-1时，min.insync.replicas指定replicas的最小数目（必须确认每一个repica的写数据都是成功的），如果这个数目没有达到，producer发送消息会产生异常 |
| delete.topic.enable        | false                           | 是否允许删除主题                                             |

# 基本操作

<span style="color:red">以下所有的命令脚本都有一些附加的选项；当我们使用[脚本 --help]运行命令脚本的时候，将会显示出这个命令的详细用法。</span>

### 创建主题(Topic)

```shell
#表示运行bin/kafka-topics.sh脚本;
#--create表示创建
#--zookeeper 192.168.124.16:2181 表示指定zookeeper服务host:port
#--replication-factor 1 表示指定副本因子为1
#--partitions 1 表示指定分区数为1
#--topic hellKafka 表示此次创建topic名称为"hellKafka"
bin/kafka-topics.sh --create --zookeeper 192.168.124.16:2181 --replication-factor 1 --partitions 1 --topic hellKafka              
```

创建成功提示如下:

```shell
[root@localhost kafka_2.11-1.1.0]# bin/kafka-topics.sh --create --zookeeper 192.168.124.16:2181 --replication-factor 1 --partitions 1 --topic hellKafka
OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N
Created topic "hellKafka".
```

除了我们通过手工的方式创建Topic，当producer发布一个消息到某个指定的Topic，这个Topic如果不存在，就自动创建。

### 删除主题

```shell
#表示运行bin/kafka-topics.sh脚本;
#--delete:删除
#--topic hellKafka:主题名称
#--zookeeper 192.168.124.16:2181 :指定zookeeper服务host:port
bin/kafka-topics.sh --delete --topic hellKafka --zookeeper 192.168.124.16:2181              
```

### 发送消息

kafka自带了一个producer命令客户端，可以从本地文件中读取内容，或者我们也可以以命令行中直接输入内容，并将这些内容以消息的形式发送到kafka集群中。在默认情况下，每一个行会被当做成一个独立的消息。

首先我们要运行发布消息的脚本，然后在命令中输入要发送的消息的内容:

```shell
#表示运行bin/kafka-console-producer.sh脚本;
#--broker-list  192.168.124.16:9092:指定kafka服务的ip和端口
#--topic hellKafka:主题名称
bin/kafka-console-producer.sh --broker-list 192.168.124.16:9092 --topic hellKafka
#发送消息
>this is a msg
#发送消息
>this is a another msg
```

### 消费消息

对于consumer，kafka同样也携带了一个命令行客户端，会将获取到内容在命令中进行输出，**默认是消费最新的消息**：

```shell
#表示运行bin/kafka-console-consumer.sh脚本;
#--bootstrap-server 192.168.124.16:9092:指定kafka服务的ip和端口
#--topic hellKafka:主题名称
bin/kafka-console-consumer.sh --bootstrap-server 192.168.124.16:9092 --topic hellKafka
```

如果想要消费之前的消息可以通过--from-beginning参数指定，如下命令：

```shell
#表示运行bin/kafka-console-consumer.sh脚本;
#--bootstrap-server 192.168.124.16:9092:指定kafka服务ip和端口
#--from-beginning:从主题partitions最开始消费
#--topic hellKafka:主题名称
bin/kafka-console-consumer.sh --bootstrap-server 192.168.124.16:9092 --from-beginning --topic hellKafka 
```

如果你是通过不同的终端窗口来运行以上的命令，你将会看到在producer终端输入的内容，很快就会在consumer的终端窗口上显示出来。

#### **消费多主题**

```shell
#表示运行bin/kafka-console-consumer.sh脚本;
#--bootstrap-server 192.168.124.16:9092:指定kafka服务ip和端口
#--whitelist "hellKafka|hellKafka2" :同时消费hellKafka,hellKafka2两个主题
bin/kafka-console-consumer.sh --bootstrap-server 192.168.124.16:9092 --whitelist "hellKafka|hellKafka2"
```

#### **单播消费**

一条消息只能被某一个消费者消费的模式，类似queue模式，只需让所有消费者在同一个消费组里即可

分别在两个客户端执行如下消费命令，然后往主题里发送消息，结果只有一个客户端能收到消息

```shell
bin/kafka-console-consumer.sh --bootstrap-server 192.168.124.16:9092  --consumer-property group.id=testGroup --topic hellKafka
```

#### **多播消费**

一条消息能被多个消费者消费的模式，类似publish-subscribe模式费，针对Kafka同一条消息只能被同一个消费组下的某一个消费者消费的特性，要实现多播只要保证这些消费者属于不同的消费组即可。我们再增加一个消费者，该消费者属于testGroup-2消费组，结果两个客户端都能收到消息

```shell
bin/kafka-console-consumer.sh --bootstrap-server 192.168.124.16:9092 --consumer-property group.id=testGroup2 --topic hellKafka
```

### 查看命令

#### 查看进程

```shell
jps
```

#### 查看主题

##### 查看zookeeper中所有的主题列表

```shell
#表示运行bin/kafka-topics.sh脚本;
#--list:显示topic列表
#--zookeeper 192.168.124.16:2181 表示指定zookeeper host:port
bin/kafka-topics.sh --list --zookeeper 192.168.124.16:2181
```
##### 查看某个主题的信息


```shell
#表示运行bin/kafka-topics.sh脚本;
#--list:显示topic列表
#--zookeeper 192.168.124.16:2181 表示指定zookeeper host:port
bin/kafka-topics.sh --describe --zookeeper 192.168.124.16:2181 --topic hellKafka2
```

![image-20210117215200261](https://gitee.com/Zeebrary/PicBed/raw/master/img/image-20210117215200261.png)

以下是输出内容的解释，第一行是所有分区的概要信息，之后的每一行表示每一个partition的信息。

- **leader**节点负责给定partition的所有读写请求。
- **replicas**表示某个partition在哪几个broker上存在备份。不管这个几点是不是”leader“，甚至这个节点挂了，也会列出。
- **isr**是replicas的一个子集，它只列出当前还存活着的，并且**已同步备份**了该partition的节点。

#### 查看分区(partition)

前面说到,partition就是磁盘中的一个commit log文件,文件路径在broker启动时指定的config/server.properties中指定的log.dirs下,进入此路径可看到如下:

![image-20210117220058350](https://gitee.com/Zeebrary/PicBed/raw/master/img/image-20210117220058350.png)

其中hellKafka-0代表topic为hellKafka的partition 0分区对应文件,可进入此文件夹：

![image-20210117221510375](https://gitee.com/Zeebrary/PicBed/raw/master/img/image-20210117221510375.png)

其中`0000000000000.log`为commit log日志,记录了生产者发布的消息,比如生产一条21的消息

![image-20210117221635911](https://gitee.com/Zeebrary/PicBed/raw/master/img/image-20210117221635911.png)

#### 查看消费组名

```shell
#执行bin/kafka-consumer-groups.sh脚本
#--bootstrap-server 192.168.124.16:9092 : 指定kafka服务ip:port
#--list : 显示所有消费组列表
bin/kafka-consumer-groups.sh --bootstrap-server 192.168.124.16:9092 --list
```

#### 查看消费组的消费偏移量

```shell
#执行bin/kafka-consumer-groups.sh脚本
#--bootstrap-server 192.168.124.16:9092 : 指定kafka服务ip:port
#--describe:描述
#--group testGroup:通过消费组名称指定消费组 group1
bin/kafka-consumer-groups.sh --bootstrap-server 192.168.124.16:9092 --describe --group group1
```

![image-20210117232140784](C:\Users\zee\AppData\Roaming\Typora\typora-user-images\image-20210117232140784.png)

**partition：**消费的topic分区

**current-offset：**当前消费组的已消费偏移量

**log-end-offset：**主题对应分区消息的结束偏移量(HW)

**lag：**当前消费组未消费的消息数